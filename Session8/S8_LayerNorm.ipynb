{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aO-7t1Y7-hV4"
   },
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "8kH16rnZ7wt_"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\anaconda3\\envs\\sdv_env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ky3f_Odl-7um"
   },
   "source": [
    "## Data Transformations\n",
    "\n",
    "We first start with defining our data transformations. We need to think what our data is and how can we augment it to correct represent images which it might not see otherwise.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "YtssFUKb-jqx"
   },
   "outputs": [],
   "source": [
    "# Train Phase transformations\n",
    "train_transforms = transforms.Compose([\n",
    "                                      #  transforms.Resize((28, 28)),\n",
    "                                    #    transforms.ColorJitter(brightness=0.10, contrast=0.1, saturation=0.10, hue=0.1),\n",
    "                                       transforms.RandomRotation((-15.0, 15.0), fill=(1,1,1)),\n",
    "                                       transforms.ToTensor(),\n",
    "                                       transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)) # The mean and std have to be sequences (e.g., tuples), therefore you should add a comma after the values.\n",
    "                                       # Note the difference between (0.1307) and (0.1307,)\n",
    "                                       ])\n",
    "\n",
    "# Test Phase transformations\n",
    "test_transforms = transforms.Compose([\n",
    "                                      #  transforms.Resize((28, 28)),\n",
    "                                      #  transforms.ColorJitter(brightness=0.10, contrast=0.1, saturation=0.10, hue=0.1),\n",
    "                                       transforms.ToTensor(),\n",
    "                                       transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "                                       ])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oQciFYo2B1mO"
   },
   "source": [
    "# Dataset and Creating Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "_4A84rlfDA23"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# from utils import get_mnist_data\n",
    "# train, test = get_mnist_data(train_transforms, test_transforms)\n",
    "train = datasets.CIFAR10('./data', train=True, download=True, transform=train_transforms)\n",
    "test = datasets.CIFAR10('./data', train=False, download=True, transform=test_transforms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qgldp_3-Dn0c"
   },
   "source": [
    "# Dataloader Arguments & Test/Train Dataloaders\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C8OLDR79DrHG",
    "outputId": "e139bd6b-e82f-485b-97b8-36e0c3767cb6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Available? True\n"
     ]
    }
   ],
   "source": [
    "SEED = 1\n",
    "\n",
    "# CUDA?\n",
    "cuda = torch.cuda.is_available()\n",
    "print(\"CUDA Available?\", cuda)\n",
    "\n",
    "# For reproducibility\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "if cuda:\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "\n",
    "# dataloader arguments - something you'll fetch these from cmdprmt\n",
    "dataloader_args = dict(shuffle=True, batch_size=128, num_workers=4, pin_memory=True) if cuda else dict(shuffle=True, batch_size=64)\n",
    "\n",
    "# train dataloader\n",
    "train_loader = torch.utils.data.DataLoader(train, **dataloader_args)\n",
    "\n",
    "# test dataloader\n",
    "test_loader = torch.utils.data.DataLoader(test, **dataloader_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ubQL3H6RJL3h"
   },
   "source": [
    "# The model\n",
    "Let's start with the model we first saw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "7FXQlB9kH1ov"
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "dropout_value = 0.05\n",
    "# from model import Model_4\n",
    "class Model_4(nn.Module):\n",
    "    def __init__(self, normal=\"bn\"):\n",
    "        super(Model_4, self).__init__()\n",
    "        \n",
    "\n",
    "        # Input Block\n",
    "        self.convblock1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=8, kernel_size=(3, 3), padding=1, bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(8),\n",
    "            nn.Dropout(dropout_value)\n",
    "        ) # output_size = 26\n",
    "\n",
    "        \n",
    "        # CONVOLUTION BLOCK 2\n",
    "\n",
    "        self.convblock2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=8, out_channels=8, kernel_size=(3, 3), padding=1, bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(8),\n",
    "            nn.Dropout(dropout_value)\n",
    "        ) # output_size = 24\n",
    "\n",
    "        # CONVOLUTION BLOCK 3\n",
    "\n",
    "        self.convblock3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=8, out_channels=8, kernel_size=(3, 3), padding=1, bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(8),\n",
    "            nn.Dropout(dropout_value)\n",
    "        ) # output_size = 24\n",
    "        \n",
    "        # TRANSITION BLOCK 1\n",
    "        self.tranblock1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=8, out_channels=16, kernel_size=(1, 1), padding=0, bias=False),\n",
    "        ) # output_size = 24\n",
    "        self.pool1 = nn.MaxPool2d(2, 2) # output_size = 12\n",
    "\n",
    "\n",
    "        # CONVOLUTION BLOCK 4\n",
    "\n",
    "        self.convblock4 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=16, out_channels=16, kernel_size=(3, 3), padding=1, bias=False),\n",
    "            nn.ReLU(),            \n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.Dropout(dropout_value)\n",
    "        ) # output_size = 10\n",
    "        \n",
    "        \n",
    "        # CONVOLUTION BLOCK 5\n",
    "\n",
    "        self.convblock5 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=16, out_channels=16, kernel_size=(3, 3), padding=1, bias=False),\n",
    "            nn.ReLU(),            \n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.Dropout(dropout_value)\n",
    "        ) # output_size = 8\n",
    "        \n",
    "        # CONVOLUTION BLOCK 6\n",
    "\n",
    "        self.convblock6 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=16, out_channels=16, kernel_size=(3, 3), padding=1, bias=False),\n",
    "            nn.ReLU(),            \n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.Dropout(dropout_value)\n",
    "        ) # output_size = 8\n",
    "        self.tranblock2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=(1, 1), padding=0, bias=False),\n",
    "        ) # output_size = 6\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        # CONVOLUTION BLOCK 7\n",
    "\n",
    "        self.convblock7 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=(3, 3), padding=1, bias=False),\n",
    "            nn.ReLU(),            \n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.Dropout(dropout_value)\n",
    "        ) # output_size = 10\n",
    "        \n",
    "        # CONVOLUTION BLOCK 8\n",
    "\n",
    "        self.convblock8 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=(3, 3), padding=1, bias=False),\n",
    "            nn.ReLU(),            \n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.Dropout(dropout_value)\n",
    "        ) # output_size = 8\n",
    "        \n",
    "        \n",
    "        # CONVOLUTION BLOCK 9\n",
    "\n",
    "        self.convblock9 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=(3, 3), padding=1, bias=False),\n",
    "            nn.ReLU(),            \n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.Dropout(dropout_value)\n",
    "        ) # output_size = 8\n",
    "        self.tranblock3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=32, out_channels=16, kernel_size=(1, 1), padding=0, bias=False),\n",
    "        )\n",
    "\n",
    "        # GAP BLOCK\n",
    "        self.gap = nn.Sequential(\n",
    "            nn.AvgPool2d(kernel_size=8)\n",
    "        ) # output_size = 1\n",
    "\n",
    "        # CONVOLUTION BLOCK 10\n",
    "        self.convblock10 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=16, out_channels=10, kernel_size=(1, 1), padding=0, bias=False),\n",
    "            # nn.BatchNorm2d(10),\n",
    "            # nn.ReLU(),\n",
    "            # nn.Dropout(dropout_value)\n",
    "        ) \n",
    "\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout_value)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.convblock1(x)\n",
    "        x = self.convblock2(x1)\n",
    "        x = self.convblock3(x) + x1\n",
    "        x = self.tranblock1(x)\n",
    "        x = self.pool1(x)\n",
    "        x1 = self.convblock4(x)\n",
    "        x = self.convblock5(x1)\n",
    "        x = self.convblock6(x) + x1\n",
    "        x = self.tranblock2(x)\n",
    "        x = self.pool2(x)\n",
    "        x1 = self.convblock7(x)\n",
    "        x = self.convblock8(x1)\n",
    "        x = self.convblock9(x) + x1\n",
    "        x = self.tranblock3(x)\n",
    "        x = self.gap(x)       \n",
    "        x = self.convblock10(x)\n",
    "\n",
    "        x = x.view(-1, 10)\n",
    "        return F.log_softmax(x, dim=-1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M3-vp8X9LCWo"
   },
   "source": [
    "# Model Params\n",
    "Can't emphasize on how important viewing Model Summary is.\n",
    "Unfortunately, there is no in-built model visualizer, so we have to take external help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5skB97zIJQQe",
    "outputId": "9dd79c22-423d-4dd1-8321-45b239f3c5f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [-1, 8, 32, 32]             216\n",
      "              ReLU-2            [-1, 8, 32, 32]               0\n",
      "       BatchNorm2d-3            [-1, 8, 32, 32]              16\n",
      "           Dropout-4            [-1, 8, 32, 32]               0\n",
      "            Conv2d-5            [-1, 8, 32, 32]             576\n",
      "              ReLU-6            [-1, 8, 32, 32]               0\n",
      "       BatchNorm2d-7            [-1, 8, 32, 32]              16\n",
      "           Dropout-8            [-1, 8, 32, 32]               0\n",
      "            Conv2d-9            [-1, 8, 32, 32]             576\n",
      "             ReLU-10            [-1, 8, 32, 32]               0\n",
      "      BatchNorm2d-11            [-1, 8, 32, 32]              16\n",
      "          Dropout-12            [-1, 8, 32, 32]               0\n",
      "           Conv2d-13           [-1, 16, 32, 32]             128\n",
      "        MaxPool2d-14           [-1, 16, 16, 16]               0\n",
      "           Conv2d-15           [-1, 16, 16, 16]           2,304\n",
      "             ReLU-16           [-1, 16, 16, 16]               0\n",
      "      BatchNorm2d-17           [-1, 16, 16, 16]              32\n",
      "          Dropout-18           [-1, 16, 16, 16]               0\n",
      "           Conv2d-19           [-1, 16, 16, 16]           2,304\n",
      "             ReLU-20           [-1, 16, 16, 16]               0\n",
      "      BatchNorm2d-21           [-1, 16, 16, 16]              32\n",
      "          Dropout-22           [-1, 16, 16, 16]               0\n",
      "           Conv2d-23           [-1, 16, 16, 16]           2,304\n",
      "             ReLU-24           [-1, 16, 16, 16]               0\n",
      "      BatchNorm2d-25           [-1, 16, 16, 16]              32\n",
      "          Dropout-26           [-1, 16, 16, 16]               0\n",
      "           Conv2d-27           [-1, 32, 16, 16]             512\n",
      "        MaxPool2d-28             [-1, 32, 8, 8]               0\n",
      "           Conv2d-29             [-1, 32, 8, 8]           9,216\n",
      "             ReLU-30             [-1, 32, 8, 8]               0\n",
      "      BatchNorm2d-31             [-1, 32, 8, 8]              64\n",
      "          Dropout-32             [-1, 32, 8, 8]               0\n",
      "           Conv2d-33             [-1, 32, 8, 8]           9,216\n",
      "             ReLU-34             [-1, 32, 8, 8]               0\n",
      "      BatchNorm2d-35             [-1, 32, 8, 8]              64\n",
      "          Dropout-36             [-1, 32, 8, 8]               0\n",
      "           Conv2d-37             [-1, 32, 8, 8]           9,216\n",
      "             ReLU-38             [-1, 32, 8, 8]               0\n",
      "      BatchNorm2d-39             [-1, 32, 8, 8]              64\n",
      "          Dropout-40             [-1, 32, 8, 8]               0\n",
      "           Conv2d-41             [-1, 16, 8, 8]             512\n",
      "        AvgPool2d-42             [-1, 16, 1, 1]               0\n",
      "           Conv2d-43             [-1, 10, 1, 1]             160\n",
      "================================================================\n",
      "Total params: 37,576\n",
      "Trainable params: 37,576\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 1.55\n",
      "Params size (MB): 0.14\n",
      "Estimated Total Size (MB): 1.71\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# !pip install torchsummary\n",
    "from torchsummary import summary\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "print(device)\n",
    "model = Model_4().to(device)\n",
    "summary(model, input_size=(3, 32, 32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1__x_SbrL7z3"
   },
   "source": [
    "# Training and Testing\n",
    "\n",
    "All right, so we have 24M params, and that's too many, we know that. But the purpose of this notebook is to set things right for our future experiments.\n",
    "\n",
    "Looking at logs can be boring, so we'll introduce **tqdm** progressbar to get cooler logs.\n",
    "\n",
    "Let's write train and test functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "fbkF2nN_LYIb"
   },
   "outputs": [],
   "source": [
    "# from utils import train, test\n",
    "\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "train_acc = []\n",
    "test_acc = []\n",
    "\n",
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "  model.train()\n",
    "  pbar = tqdm(train_loader)\n",
    "  correct = 0\n",
    "  processed = 0\n",
    "  for batch_idx, (data, target) in enumerate(pbar):\n",
    "    # get samples\n",
    "    data, target = data.to(device), target.to(device)\n",
    "\n",
    "    # Init\n",
    "    optimizer.zero_grad()\n",
    "    # In PyTorch, we need to set the gradients to zero before starting to do backpropragation because PyTorch accumulates the gradients on subsequent backward passes.\n",
    "    # Because of this, when you start your training loop, ideally you should zero out the gradients so that you do the parameter update correctly.\n",
    "\n",
    "    # Predict\n",
    "    y_pred = model(data)\n",
    "\n",
    "    # Calculate loss\n",
    "    loss = F.nll_loss(y_pred, target)\n",
    "    train_losses.append(loss)\n",
    "\n",
    "    # Backpropagation\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Update pbar-tqdm\n",
    "\n",
    "    pred = y_pred.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "    correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "    processed += len(data)\n",
    "\n",
    "    pbar.set_description(desc= f'Loss={loss.item()} Batch_id={batch_idx} Accuracy={100*correct/processed:0.2f}')\n",
    "    train_acc.append(100*correct/processed)\n",
    "\n",
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    test_losses.append(test_loss)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "\n",
    "    test_acc.append(100. * correct / len(test_loader.dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aE5Le6FYHhc8",
    "outputId": "661fcdc4-a038-4376-dfdd-da4f9722ffa4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=1.3798052072525024 Batch_id=390 Accuracy=40.59: 100%|███████████████████████████| 391/391 [00:15<00:00, 25.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 1.3765, Accuracy: 4907/10000 (49.07%)\n",
      "\n",
      "EPOCH: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=1.308971643447876 Batch_id=390 Accuracy=52.82: 100%|████████████████████████████| 391/391 [00:14<00:00, 26.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 1.4083, Accuracy: 5134/10000 (51.34%)\n",
      "\n",
      "EPOCH: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=1.3459490537643433 Batch_id=390 Accuracy=58.26: 100%|███████████████████████████| 391/391 [00:14<00:00, 27.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 1.1167, Accuracy: 5958/10000 (59.58%)\n",
      "\n",
      "EPOCH: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=1.0483582019805908 Batch_id=390 Accuracy=61.93: 100%|███████████████████████████| 391/391 [00:14<00:00, 26.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 1.0918, Accuracy: 6107/10000 (61.07%)\n",
      "\n",
      "EPOCH: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.961347222328186 Batch_id=390 Accuracy=64.60: 100%|████████████████████████████| 391/391 [00:14<00:00, 27.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.9299, Accuracy: 6659/10000 (66.59%)\n",
      "\n",
      "EPOCH: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.7553361058235168 Batch_id=390 Accuracy=69.33: 100%|███████████████████████████| 391/391 [00:14<00:00, 27.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.8487, Accuracy: 6939/10000 (69.39%)\n",
      "\n",
      "EPOCH: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=1.0297825336456299 Batch_id=390 Accuracy=70.15: 100%|███████████████████████████| 391/391 [00:14<00:00, 27.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.8257, Accuracy: 7068/10000 (70.68%)\n",
      "\n",
      "EPOCH: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.9469733238220215 Batch_id=390 Accuracy=70.80: 100%|███████████████████████████| 391/391 [00:14<00:00, 26.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.8041, Accuracy: 7159/10000 (71.59%)\n",
      "\n",
      "EPOCH: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.7960101366043091 Batch_id=390 Accuracy=71.41: 100%|███████████████████████████| 391/391 [00:14<00:00, 27.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.7973, Accuracy: 7187/10000 (71.87%)\n",
      "\n",
      "EPOCH: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.835424542427063 Batch_id=390 Accuracy=71.54: 100%|████████████████████████████| 391/391 [00:15<00:00, 25.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.7905, Accuracy: 7196/10000 (71.96%)\n",
      "\n",
      "EPOCH: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.9278632998466492 Batch_id=390 Accuracy=72.25: 100%|███████████████████████████| 391/391 [00:14<00:00, 26.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.7836, Accuracy: 7243/10000 (72.43%)\n",
      "\n",
      "EPOCH: 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.6024354696273804 Batch_id=390 Accuracy=72.37: 100%|███████████████████████████| 391/391 [00:14<00:00, 27.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.7834, Accuracy: 7217/10000 (72.17%)\n",
      "\n",
      "EPOCH: 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.8467873334884644 Batch_id=390 Accuracy=72.20: 100%|███████████████████████████| 391/391 [00:14<00:00, 26.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.7793, Accuracy: 7249/10000 (72.49%)\n",
      "\n",
      "EPOCH: 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.7034211158752441 Batch_id=390 Accuracy=72.44: 100%|███████████████████████████| 391/391 [00:14<00:00, 26.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.7746, Accuracy: 7261/10000 (72.61%)\n",
      "\n",
      "EPOCH: 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.6986692547798157 Batch_id=390 Accuracy=72.68: 100%|███████████████████████████| 391/391 [00:15<00:00, 25.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.7804, Accuracy: 7248/10000 (72.48%)\n",
      "\n",
      "EPOCH: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.8723853826522827 Batch_id=390 Accuracy=72.57: 100%|███████████████████████████| 391/391 [00:15<00:00, 24.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.7782, Accuracy: 7263/10000 (72.63%)\n",
      "\n",
      "EPOCH: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.7118234038352966 Batch_id=390 Accuracy=72.44: 100%|███████████████████████████| 391/391 [00:15<00:00, 25.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.7767, Accuracy: 7249/10000 (72.49%)\n",
      "\n",
      "EPOCH: 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.6645475625991821 Batch_id=390 Accuracy=72.30: 100%|███████████████████████████| 391/391 [00:15<00:00, 25.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.7749, Accuracy: 7260/10000 (72.60%)\n",
      "\n",
      "EPOCH: 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.5948140621185303 Batch_id=390 Accuracy=72.55: 100%|███████████████████████████| 391/391 [00:14<00:00, 26.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.7800, Accuracy: 7238/10000 (72.38%)\n",
      "\n",
      "EPOCH: 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.8665997385978699 Batch_id=390 Accuracy=72.78: 100%|███████████████████████████| 391/391 [00:15<00:00, 24.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.7793, Accuracy: 7248/10000 (72.48%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "model =  Model_4().to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.08, momentum=0.9)\n",
    "scheduler = StepLR(optimizer, step_size=5, gamma=0.1)\n",
    "\n",
    "\n",
    "EPOCHS = 20\n",
    "for epoch in range(EPOCHS):\n",
    "    print(\"EPOCH:\", epoch)\n",
    "    train(model, device, train_loader, optimizer, epoch)\n",
    "    scheduler.step()\n",
    "    test(model, device, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fKeBz_bFDIBd"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "sdv_env",
   "language": "python",
   "name": "sdv_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
